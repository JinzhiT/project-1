{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\\\n",
        "Project 1"
      ],
      "metadata": {
        "id": "9fm9P3VE85Y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Python and Google Colab\n",
        "Project Euler Problem  \n",
        "https://projecteuler.net/"
      ],
      "metadata": {
        "id": "voDhElnJXDro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "y_e6lM_NEwwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Regression Analysis\n",
        "California housing data  \n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n"
      ],
      "metadata": {
        "id": "riLtqhJEXNOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5gtRmgu1kL6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing data\n",
        "cal = fetch_california_housing(as_frame=True)\n",
        "X, y = cal.data, cal.target\n",
        "feature_names = X.columns\n",
        "print(feature_names)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "metadata": {
        "id": "YdjNvnAGkRpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f703a8-5008-4b11-8dc9-a3636d7efd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
            "       'Latitude', 'Longitude'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# ---- Load the extracted StatLib California Housing data ----\n",
        "data_file = \"/mnt/data/CaliforniaHousing/cal_housing.data\"  # adjust if your path differs\n",
        "\n",
        "# Correct StatLib column order\n",
        "cols = [\n",
        "    \"Longitude\", \"Latitude\", \"HouseAge\", \"TotalRooms\",\n",
        "    \"TotalBedrooms\", \"Population\", \"Households\",\n",
        "    \"MedInc\", \"MedHouseVal\"\n",
        "]\n",
        "df = pd.read_csv(data_file, header=None, names=cols).dropna()\n",
        "\n",
        "# Features/target\n",
        "feature_cols = [\"MedInc\", \"HouseAge\", \"TotalRooms\", \"TotalBedrooms\",\n",
        "                \"Population\", \"Households\", \"Latitude\", \"Longitude\"]\n",
        "X = df[feature_cols]\n",
        "y = df[\"MedHouseVal\"]  # in US dollars\n",
        "\n",
        "# Provided split spec (20% test, random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=0\n",
        ")\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"R2\": r2_score(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
        "    }\n",
        "\n",
        "# ---- 1) Linear Regression (OLS) ----\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "lin_train = metrics(y_train, linreg.predict(X_train))\n",
        "lin_test  = metrics(y_test,  linreg.predict(X_test))\n",
        "\n",
        "# ---- 2) Random Forest ----\n",
        "rf = RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_train = metrics(y_train, rf.predict(X_train))\n",
        "rf_test  = metrics(y_test,  rf.predict(X_test))\n",
        "\n",
        "# ---- 3) Gradient Boosting ----\n",
        "gbr = GradientBoostingRegressor(random_state=0).fit(X_train, y_train)\n",
        "gbr_train = metrics(y_train, gbr.predict(X_train))\n",
        "gbr_test  = metrics(y_test,  gbr.predict(X_test))\n",
        "\n",
        "# ---- Pick best model by Test R^2 and make plots ----\n",
        "model_preds = {\n",
        "    \"Linear\": linreg.predict(X_test),\n",
        "    \"RandomForest\": rf.predict(X_test),\n",
        "    \"GradientBoosting\": gbr.predict(X_test),\n",
        "}\n",
        "best_name = max(model_preds, key=lambda k: r2_score(y_test, model_preds[k]))\n",
        "best_pred = model_preds[best_name]\n",
        "\n",
        "# Scatter: predicted vs true\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, best_pred, alpha=0.3)\n",
        "lims = [min(y_test.min(), best_pred.min()), max(y_test.max(), best_pred.max())]\n",
        "plt.plot(lims, lims)  # 45-degree line\n",
        "plt.xlabel(\"True Median House Value (USD)\")\n",
        "plt.ylabel(\"Predicted Median House Value (USD)\")\n",
        "plt.title(f\"Predicted vs True (Best: {best_name})\")\n",
        "plt.savefig(\"scatter_pred_true.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Error histogram\n",
        "errors = best_pred - y_test\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(errors, bins=40, edgecolor=\"black\")\n",
        "plt.xlabel(\"Prediction Error (USD)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(f\"Error Histogram ({best_name})\")\n",
        "plt.savefig(\"error_histogram.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ---- Summaries ----\n",
        "import pandas as pd\n",
        "summary = pd.DataFrame({\n",
        "    (\"Linear\",\"Train\"): lin_train,\n",
        "    (\"Linear\",\"Test\"):  lin_test,\n",
        "    (\"RandomForest\",\"Train\"): rf_train,\n",
        "    (\"RandomForest\",\"Test\"):  rf_test,\n",
        "    (\"GradientBoosting\",\"Train\"): gbr_train,\n",
        "    (\"GradientBoosting\",\"Test\"):  gbr_test,\n",
        "}).T\n",
        "print(\"Regression metrics (R2, MAE, RMSE):\")\n",
        "print(summary.round(3))\n",
        "\n",
        "# Feature importance (best model)\n",
        "if best_name in [\"RandomForest\", \"GradientBoosting\"]:\n",
        "    importances = pd.Series(eval(best_name.lower()).feature_importances_,\n",
        "                            index=feature_cols).sort_values(ascending=False)\n",
        "else:\n",
        "    # absolute standardized coefficients for linear model\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    coefs = LinearRegression().fit(scaler.transform(X_train), y_train).coef_\n",
        "    importances = pd.Series(np.abs(coefs), index=feature_cols).sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nFeature importance (best model):\")\n",
        "print(importances.round(4))\n"
      ],
      "metadata": {
        "id": "PEYTEFsSXMk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Classification Analysis\n",
        "Diagnostic Wisconsin Breast Cancer Database  \n",
        "https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset"
      ],
      "metadata": {
        "id": "QkSVMB7HXSZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "vUfQhEk7zQBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Breast Cancer Wisconsin Dataset\n",
        "data = load_breast_cancer(as_frame=True)\n",
        "X = data.data\n",
        "y = data.target                  # 0 = malignant, 1 = benign\n",
        "feature_names = X.columns\n",
        "label_names = {0: \"malignant\", 1: \"benign\"}\n",
        "print(feature_names)\n",
        "\n",
        "# Train/Test Split (stratified to preserve class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
        "\n",
        "# Preprocess Data (fit on train ONLY; then transform both)\n",
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "X_train_std = scaler.fit_transform(X_train)   # fit on train\n",
        "X_test_std  = scaler.transform(X_test)        # transform test with train stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGeihULRzZxD",
        "outputId": "b7cff0d4-9149-4208-c92c-6fedb809d25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
            "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
            "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
            "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "QUYeDq2ZXY2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}