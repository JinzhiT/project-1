{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinzhiT/project-1/blob/main/project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\\\n",
        "Project 1"
      ],
      "metadata": {
        "id": "9fm9P3VE85Y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Python and Google Colab\n",
        "Project Euler Problem  \n",
        "https://projecteuler.net/"
      ],
      "metadata": {
        "id": "voDhElnJXDro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = sum(i for i in range(1000) if i % 3 == 0 or i % 5 == 0)\n",
        "print(total)"
      ],
      "metadata": {
        "id": "y_e6lM_NEwwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Regression Analysis\n",
        "California housing data  \n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n"
      ],
      "metadata": {
        "id": "riLtqhJEXNOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5gtRmgu1kL6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing data\n",
        "cal = fetch_california_housing(as_frame=True)\n",
        "X, y = cal.data, cal.target\n",
        "feature_names = X.columns\n",
        "print(feature_names)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "metadata": {
        "id": "YdjNvnAGkRpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f703a8-5008-4b11-8dc9-a3636d7efd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
            "       'Latitude', 'Longitude'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Extract and load the dataset\n",
        "# -------------------------------\n",
        "\n",
        "# Path to tgz file (make sure cal_housing.tgz is in the same folder as notebook)\n",
        "tgz_path = \"cal_housing.tgz\"\n",
        "\n",
        "# Extract tgz\n",
        "with tarfile.open(tgz_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=\".\")\n",
        "\n",
        "# Check extracted files\n",
        "print(\"Extracted files in ./CaliforniaHousing:\", os.listdir(\"./CaliforniaHousing\"))\n",
        "\n",
        "# Load dataset\n",
        "data_file = \"./CaliforniaHousing/cal_housing.data\"\n",
        "\n",
        "cols = [\n",
        "    \"Longitude\", \"Latitude\", \"HouseAge\", \"TotalRooms\",\n",
        "    \"TotalBedrooms\", \"Population\", \"Households\",\n",
        "    \"MedInc\", \"MedHouseVal\"\n",
        "]\n",
        "df = pd.read_csv(data_file, header=None, names=cols).dropna()\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Train/test split\n",
        "# -------------------------------\n",
        "feature_cols = [\n",
        "    \"MedInc\", \"HouseAge\", \"TotalRooms\", \"TotalBedrooms\",\n",
        "    \"Population\", \"Households\", \"Latitude\", \"Longitude\"\n",
        "]\n",
        "X = df[feature_cols]\n",
        "y = df[\"MedHouseVal\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=0\n",
        ")\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"R2\": r2_score(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Models\n",
        "# -------------------------------\n",
        "\n",
        "# Linear Regression\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "lin_train = metrics(y_train, linreg.predict(X_train))\n",
        "lin_test  = metrics(y_test,  linreg.predict(X_test))\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_train = metrics(y_train, rf.predict(X_train))\n",
        "rf_test  = metrics(y_test,  rf.predict(X_test))\n",
        "\n",
        "# Gradient Boosting\n",
        "gbr = GradientBoostingRegressor(random_state=0).fit(X_train, y_train)\n",
        "gbr_train = metrics(y_train, gbr.predict(X_train))\n",
        "gbr_test  = metrics(y_test,  gbr.predict(X_test))\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Pick best model and plot\n",
        "# -------------------------------\n",
        "model_preds = {\n",
        "    \"Linear\": linreg.predict(X_test),\n",
        "    \"RandomForest\": rf.predict(X_test),\n",
        "    \"GradientBoosting\": gbr.predict(X_test),\n",
        "}\n",
        "best_name = max(model_preds, key=lambda k: r2_score(y_test, model_preds[k]))\n",
        "best_pred = model_preds[best_name]\n",
        "\n",
        "print(\"\\nBest model based on Test R2:\", best_name)\n",
        "\n",
        "# Scatterplot\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, best_pred, alpha=0.3)\n",
        "lims = [min(y_test.min(), best_pred.min()), max(y_test.max(), best_pred.max())]\n",
        "plt.plot(lims, lims, 'r--')  # 45-degree line\n",
        "plt.xlabel(\"True Median House Value (USD)\")\n",
        "plt.ylabel(\"Predicted Median House Value (USD)\")\n",
        "plt.title(f\"Predicted vs True ({best_name})\")\n",
        "plt.savefig(\"scatter_pred_true.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Error histogram\n",
        "errors = best_pred - y_test\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(errors, bins=40, edgecolor=\"black\")\n",
        "plt.xlabel(\"Prediction Error (USD)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(f\"Error Histogram ({best_name})\")\n",
        "plt.savefig(\"error_histogram.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved plots: scatter_pred_true.png, error_histogram.png\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Summaries\n",
        "# -------------------------------\n",
        "summary = pd.DataFrame({\n",
        "    (\"Linear\",\"Train\"): lin_train,\n",
        "    (\"Linear\",\"Test\"):  lin_test,\n",
        "    (\"RandomForest\",\"Train\"): rf_train,\n",
        "    (\"RandomForest\",\"Test\"):  rf_test,\n",
        "    (\"GradientBoosting\",\"Train\"): gbr_train,\n",
        "    (\"GradientBoosting\",\"Test\"):  gbr_test,\n",
        "}).T\n",
        "\n",
        "print(\"\\nRegression metrics (R2, MAE, RMSE):\")\n",
        "print(summary.round(3))\n",
        "\n",
        "# Feature importance (best model)\n",
        "if best_name in [\"RandomForest\", \"GradientBoosting\"]:\n",
        "    best_model = rf if best_name==\"RandomForest\" else gbr\n",
        "    importances = pd.Series(best_model.feature_importances_,\n",
        "                            index=feature_cols).sort_values(ascending=False)\n",
        "else:\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    coefs = LinearRegression().fit(scaler.transform(X_train), y_train).coef_\n",
        "    importances = pd.Series(np.abs(coefs), index=feature_cols).sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nFeature importance (best model):\")\n",
        "print(importances.round(4))\n"
      ],
      "metadata": {
        "id": "PEYTEFsSXMk2",
        "outputId": "fb9ca2da-4db9-45b4-9122-62b9a583abf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'cal_housing.tgz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3508455211.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Extract tgz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1870\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1872\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1920\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1921\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cal_housing.tgz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Classification Analysis\n",
        "Diagnostic Wisconsin Breast Cancer Database  \n",
        "https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset"
      ],
      "metadata": {
        "id": "QkSVMB7HXSZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "vUfQhEk7zQBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Breast Cancer Wisconsin Dataset\n",
        "data = load_breast_cancer(as_frame=True)\n",
        "X = data.data\n",
        "y = data.target                  # 0 = malignant, 1 = benign\n",
        "feature_names = X.columns\n",
        "label_names = {0: \"malignant\", 1: \"benign\"}\n",
        "print(feature_names)\n",
        "\n",
        "# Train/Test Split (stratified to preserve class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
        "\n",
        "# Preprocess Data (fit on train ONLY; then transform both)\n",
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "X_train_std = scaler.fit_transform(X_train)   # fit on train\n",
        "X_test_std  = scaler.transform(X_test)        # transform test with train stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGeihULRzZxD",
        "outputId": "b7cff0d4-9149-4208-c92c-6fedb809d25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
            "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
            "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
            "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "QUYeDq2ZXY2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}